[2021-01-21 23:13:16,704] INFO: collecting all words and their counts
[2021-01-21 23:13:16,705] WARNING: Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.
[2021-01-21 23:13:16,705] INFO: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
[2021-01-21 23:13:16,731] INFO: PROGRESS: at sentence #10000, processed 50840 words, keeping 28 word types
[2021-01-21 23:13:16,757] INFO: PROGRESS: at sentence #20000, processed 99286 words, keeping 40 word types
[2021-01-21 23:13:16,782] INFO: PROGRESS: at sentence #30000, processed 145975 words, keeping 69 word types
[2021-01-21 23:13:16,785] INFO: collected 72 word types from a corpus of 150718 raw words and 31102 sentences
[2021-01-21 23:13:16,786] INFO: Loading a fresh vocabulary
[2021-01-21 23:13:16,787] INFO: effective_min_count=1 retains 72 unique words (100% of original 72, drops 0)
[2021-01-21 23:13:16,787] INFO: effective_min_count=1 leaves 150718 word corpus (100% of original 150718, drops 0)
[2021-01-21 23:13:16,788] INFO: deleting the raw counts dictionary of 72 items
[2021-01-21 23:13:16,789] INFO: sample=0.001 downsamples 40 most-common words
[2021-01-21 23:13:16,790] INFO: downsampling leaves estimated 34584 word corpus (22.9% of prior 150718)
[2021-01-21 23:13:16,790] INFO: estimated required memory for 72 words and 100 dimensions: 93600 bytes
[2021-01-21 23:13:16,791] INFO: resetting layer weights
[2021-01-21 23:13:16,818] INFO: training model with 1 workers on 72 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
[2021-01-21 23:13:17,207] INFO: worker thread finished; awaiting finish of 0 more threads
[2021-01-21 23:13:17,207] INFO: EPOCH - 1 : training on 150718 raw words (34799 effective words) took 0.4s, 89936 effective words/s
[2021-01-21 23:13:17,596] INFO: worker thread finished; awaiting finish of 0 more threads
[2021-01-21 23:13:17,596] INFO: EPOCH - 2 : training on 150718 raw words (34588 effective words) took 0.4s, 95870 effective words/s
[2021-01-21 23:13:17,986] INFO: worker thread finished; awaiting finish of 0 more threads
[2021-01-21 23:13:17,986] INFO: EPOCH - 3 : training on 150718 raw words (34600 effective words) took 0.4s, 90549 effective words/s
[2021-01-21 23:13:18,383] INFO: worker thread finished; awaiting finish of 0 more threads
[2021-01-21 23:13:18,384] INFO: EPOCH - 4 : training on 150718 raw words (34680 effective words) took 0.4s, 88956 effective words/s
[2021-01-21 23:13:18,781] INFO: worker thread finished; awaiting finish of 0 more threads
[2021-01-21 23:13:18,782] INFO: EPOCH - 5 : training on 150718 raw words (34608 effective words) took 0.4s, 88554 effective words/s
[2021-01-21 23:13:18,782] INFO: training on a 753590 raw words (173275 effective words) took 2.0s, 88243 effective words/s
[2021-01-21 23:13:18,784] INFO: collecting all words and their counts
[2021-01-21 23:13:18,785] WARNING: Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.
[2021-01-21 23:13:18,785] INFO: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
[2021-01-21 23:13:18,963] INFO: PROGRESS: at sentence #10000, processed 444943 words, keeping 1066 word types
[2021-01-21 23:13:19,205] INFO: PROGRESS: at sentence #20000, processed 769124 words, keeping 1163 word types
[2021-01-21 23:13:19,374] INFO: PROGRESS: at sentence #30000, processed 1179471 words, keeping 1205 word types
[2021-01-21 23:13:19,395] INFO: collected 1208 word types from a corpus of 1225857 raw words and 31102 sentences
[2021-01-21 23:13:19,395] INFO: Loading a fresh vocabulary
[2021-01-21 23:13:19,408] INFO: effective_min_count=1 retains 1208 unique words (100% of original 1208, drops 0)
[2021-01-21 23:13:19,409] INFO: effective_min_count=1 leaves 1225857 word corpus (100% of original 1225857, drops 0)
[2021-01-21 23:13:19,417] INFO: deleting the raw counts dictionary of 1208 items
[2021-01-21 23:13:19,417] INFO: sample=0.001 downsamples 59 most-common words
[2021-01-21 23:13:19,418] INFO: downsampling leaves estimated 595055 word corpus (48.5% of prior 1225857)
[2021-01-21 23:13:19,424] INFO: estimated required memory for 1208 words and 100 dimensions: 1570400 bytes
[2021-01-21 23:13:19,425] INFO: resetting layer weights
[2021-01-21 23:13:19,849] INFO: training model with 1 workers on 1208 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
[2021-01-21 23:13:20,879] INFO: EPOCH 1 - PROGRESS: at 70.59% examples, 406895 words/s, in_qsize 1, out_qsize 0
[2021-01-21 23:13:21,313] INFO: worker thread finished; awaiting finish of 0 more threads
[2021-01-21 23:13:21,313] INFO: EPOCH - 1 : training on 1225857 raw words (594897 effective words) took 1.4s, 410784 effective words/s
[2021-01-21 23:13:22,326] INFO: EPOCH 2 - PROGRESS: at 69.07% examples, 401936 words/s, in_qsize 1, out_qsize 0
[2021-01-21 23:13:22,789] INFO: worker thread finished; awaiting finish of 0 more threads
[2021-01-21 23:13:22,790] INFO: EPOCH - 2 : training on 1225857 raw words (596009 effective words) took 1.5s, 406246 effective words/s
[2021-01-21 23:13:23,803] INFO: EPOCH 3 - PROGRESS: at 69.07% examples, 402749 words/s, in_qsize 1, out_qsize 0
[2021-01-21 23:13:24,267] INFO: worker thread finished; awaiting finish of 0 more threads
[2021-01-21 23:13:24,267] INFO: EPOCH - 3 : training on 1225857 raw words (595367 effective words) took 1.5s, 406609 effective words/s
[2021-01-21 23:13:25,293] INFO: EPOCH 4 - PROGRESS: at 69.89% examples, 402864 words/s, in_qsize 1, out_qsize 0
[2021-01-21 23:13:25,765] INFO: worker thread finished; awaiting finish of 0 more threads
[2021-01-21 23:13:25,765] INFO: EPOCH - 4 : training on 1225857 raw words (594955 effective words) took 1.5s, 400924 effective words/s
[2021-01-21 23:13:26,779] INFO: EPOCH 5 - PROGRESS: at 69.89% examples, 406803 words/s, in_qsize 1, out_qsize 0
[2021-01-21 23:13:27,225] INFO: worker thread finished; awaiting finish of 0 more threads
[2021-01-21 23:13:27,226] INFO: EPOCH - 5 : training on 1225857 raw words (594274 effective words) took 1.4s, 410718 effective words/s
[2021-01-21 23:13:27,226] INFO: training on a 6129285 raw words (2975502 effective words) took 7.4s, 403371 effective words/s
[2021-01-21 23:13:27,228] INFO: collecting all words and their counts
[2021-01-21 23:13:27,229] WARNING: Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.
[2021-01-21 23:13:27,229] INFO: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
[2021-01-21 23:13:27,314] INFO: PROGRESS: at sentence #10000, processed 262639 words, keeping 27 word types
[2021-01-21 23:13:27,405] INFO: PROGRESS: at sentence #20000, processed 531242 words, keeping 27 word types
[2021-01-21 23:13:27,479] INFO: PROGRESS: at sentence #30000, processed 753527 words, keeping 27 word types
[2021-01-21 23:13:27,488] INFO: collected 27 word types from a corpus of 780929 raw words and 31102 sentences
[2021-01-21 23:13:27,489] INFO: Loading a fresh vocabulary
[2021-01-21 23:13:27,490] INFO: effective_min_count=1 retains 27 unique words (100% of original 27, drops 0)
[2021-01-21 23:13:27,490] INFO: effective_min_count=1 leaves 780929 word corpus (100% of original 780929, drops 0)
[2021-01-21 23:13:27,491] INFO: deleting the raw counts dictionary of 27 items
[2021-01-21 23:13:27,491] INFO: sample=0.001 downsamples 24 most-common words
[2021-01-21 23:13:27,491] INFO: downsampling leaves estimated 132965 word corpus (17.0% of prior 780929)
[2021-01-21 23:13:27,492] INFO: estimated required memory for 27 words and 100 dimensions: 35100 bytes
[2021-01-21 23:13:27,492] INFO: resetting layer weights
[2021-01-21 23:13:27,503] INFO: training model with 1 workers on 27 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
[2021-01-21 23:13:28,115] INFO: worker thread finished; awaiting finish of 0 more threads
[2021-01-21 23:13:28,116] INFO: EPOCH - 1 : training on 780929 raw words (133016 effective words) took 0.6s, 223108 effective words/s
[2021-01-21 23:13:28,727] INFO: worker thread finished; awaiting finish of 0 more threads
[2021-01-21 23:13:28,727] INFO: EPOCH - 2 : training on 780929 raw words (132930 effective words) took 0.6s, 220824 effective words/s
[2021-01-21 23:13:29,316] INFO: worker thread finished; awaiting finish of 0 more threads
[2021-01-21 23:13:29,317] INFO: EPOCH - 3 : training on 780929 raw words (133233 effective words) took 0.6s, 229739 effective words/s
[2021-01-21 23:13:29,932] INFO: worker thread finished; awaiting finish of 0 more threads
[2021-01-21 23:13:29,933] INFO: EPOCH - 4 : training on 780929 raw words (133807 effective words) took 0.6s, 223261 effective words/s
[2021-01-21 23:13:30,549] INFO: worker thread finished; awaiting finish of 0 more threads
[2021-01-21 23:13:30,549] INFO: EPOCH - 5 : training on 780929 raw words (133240 effective words) took 0.6s, 219687 effective words/s
[2021-01-21 23:13:30,550] INFO: training on a 3904645 raw words (666226 effective words) took 3.0s, 218650 effective words/s
[2021-01-21 23:13:30,551] INFO: saving model_word2vec_bibl_bible_bcn
[2021-01-21 23:13:30,552] INFO: saving Word2Vec object under /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_word2vec_bibl_bible_bcn, separately None
[2021-01-21 23:13:30,553] INFO: not storing attribute vectors_norm
[2021-01-21 23:13:30,554] INFO: not storing attribute cum_table
[2021-01-21 23:13:30,556] INFO: saved /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_word2vec_bibl_bible_bcn
[2021-01-21 23:13:30,556] INFO: saved /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_word2vec_bibl_bible_bcn
[2021-01-21 23:13:30,556] INFO: saving model_word2vec_bibl_content
[2021-01-21 23:13:30,557] INFO: saving Word2Vec object under /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_word2vec_bibl_content, separately None
[2021-01-21 23:13:30,558] INFO: not storing attribute vectors_norm
[2021-01-21 23:13:30,558] INFO: not storing attribute cum_table
[2021-01-21 23:13:30,569] INFO: saved /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_word2vec_bibl_content
[2021-01-21 23:13:30,569] INFO: saved /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_word2vec_bibl_content
[2021-01-21 23:13:30,570] INFO: saving model_word2vec_bibl_econtent
[2021-01-21 23:13:30,570] INFO: saving Word2Vec object under /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_word2vec_bibl_econtent, separately None
[2021-01-21 23:13:30,571] INFO: not storing attribute vectors_norm
[2021-01-21 23:13:30,572] INFO: not storing attribute cum_table
[2021-01-21 23:13:30,573] INFO: saved /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_word2vec_bibl_econtent
[2021-01-21 23:13:30,574] INFO: saved /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_word2vec_bibl_econtent
[2021-01-21 23:13:30,575] INFO: resetting layer weights
[2021-01-21 23:13:39,027] INFO: collecting all words and their counts
[2021-01-21 23:13:39,028] WARNING: Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.
[2021-01-21 23:13:39,029] INFO: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
[2021-01-21 23:13:39,056] INFO: PROGRESS: at sentence #10000, processed 50840 words, keeping 28 word types
[2021-01-21 23:13:39,081] INFO: PROGRESS: at sentence #20000, processed 99286 words, keeping 40 word types
[2021-01-21 23:13:39,106] INFO: PROGRESS: at sentence #30000, processed 145975 words, keeping 69 word types
[2021-01-21 23:13:39,110] INFO: collected 72 word types from a corpus of 150718 raw words and 31102 sentences
[2021-01-21 23:13:39,110] INFO: Loading a fresh vocabulary
[2021-01-21 23:13:39,111] INFO: effective_min_count=1 retains 72 unique words (100% of original 72, drops 0)
[2021-01-21 23:13:39,111] INFO: effective_min_count=1 leaves 150718 word corpus (100% of original 150718, drops 0)
[2021-01-21 23:13:39,112] INFO: deleting the raw counts dictionary of 72 items
[2021-01-21 23:13:39,113] INFO: sample=0.001 downsamples 40 most-common words
[2021-01-21 23:13:39,113] INFO: downsampling leaves estimated 34584 word corpus (22.9% of prior 150718)
[2021-01-21 23:13:39,115] INFO: estimated required memory for 72 words, 72 buckets and 100 dimensions: 126432 bytes
[2021-01-21 23:13:39,115] INFO: resetting layer weights
[2021-01-21 23:13:43,648] INFO: training model with 1 workers on 72 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
[2021-01-21 23:13:44,085] INFO: worker thread finished; awaiting finish of 0 more threads
[2021-01-21 23:13:44,086] INFO: EPOCH - 1 : training on 150718 raw words (34799 effective words) took 0.4s, 84013 effective words/s
[2021-01-21 23:13:44,515] INFO: worker thread finished; awaiting finish of 0 more threads
[2021-01-21 23:13:44,516] INFO: EPOCH - 2 : training on 150718 raw words (34588 effective words) took 0.4s, 81704 effective words/s
[2021-01-21 23:13:44,916] INFO: worker thread finished; awaiting finish of 0 more threads
[2021-01-21 23:13:44,917] INFO: EPOCH - 3 : training on 150718 raw words (34600 effective words) took 0.4s, 87782 effective words/s
[2021-01-21 23:13:45,318] INFO: worker thread finished; awaiting finish of 0 more threads
[2021-01-21 23:13:45,327] INFO: EPOCH - 4 : training on 150718 raw words (34680 effective words) took 0.4s, 87881 effective words/s
[2021-01-21 23:13:45,755] INFO: worker thread finished; awaiting finish of 0 more threads
[2021-01-21 23:13:45,755] INFO: EPOCH - 5 : training on 150718 raw words (34608 effective words) took 0.4s, 82102 effective words/s
[2021-01-21 23:13:45,756] INFO: training on a 753590 raw words (173275 effective words) took 2.1s, 82244 effective words/s
[2021-01-21 23:13:45,760] INFO: resetting layer weights
[2021-01-21 23:13:56,543] INFO: collecting all words and their counts
[2021-01-21 23:13:56,568] WARNING: Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.
[2021-01-21 23:13:56,568] INFO: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
[2021-01-21 23:13:56,742] INFO: PROGRESS: at sentence #10000, processed 444943 words, keeping 1066 word types
[2021-01-21 23:13:56,871] INFO: PROGRESS: at sentence #20000, processed 769124 words, keeping 1163 word types
[2021-01-21 23:13:57,037] INFO: PROGRESS: at sentence #30000, processed 1179471 words, keeping 1205 word types
[2021-01-21 23:13:57,055] INFO: collected 1208 word types from a corpus of 1225857 raw words and 31102 sentences
[2021-01-21 23:13:57,055] INFO: Loading a fresh vocabulary
[2021-01-21 23:13:57,068] INFO: effective_min_count=1 retains 1208 unique words (100% of original 1208, drops 0)
[2021-01-21 23:13:57,068] INFO: effective_min_count=1 leaves 1225857 word corpus (100% of original 1225857, drops 0)
[2021-01-21 23:13:57,077] INFO: deleting the raw counts dictionary of 1208 items
[2021-01-21 23:13:57,078] INFO: sample=0.001 downsamples 59 most-common words
[2021-01-21 23:13:57,079] INFO: downsampling leaves estimated 595055 word corpus (48.5% of prior 1225857)
[2021-01-21 23:13:57,099] INFO: estimated required memory for 1208 words, 1208 buckets and 100 dimensions: 2121248 bytes
[2021-01-21 23:13:57,099] INFO: resetting layer weights
[2021-01-21 23:14:02,284] INFO: training model with 1 workers on 1208 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
[2021-01-21 23:14:03,306] INFO: EPOCH 1 - PROGRESS: at 47.98% examples, 291641 words/s, in_qsize 1, out_qsize 0
[2021-01-21 23:14:04,256] INFO: worker thread finished; awaiting finish of 0 more threads
[2021-01-21 23:14:04,257] INFO: EPOCH - 1 : training on 1225857 raw words (594897 effective words) took 2.0s, 302793 effective words/s
[2021-01-21 23:14:05,292] INFO: EPOCH 2 - PROGRESS: at 29.62% examples, 193482 words/s, in_qsize 1, out_qsize 0
[2021-01-21 23:14:06,298] INFO: EPOCH 2 - PROGRESS: at 77.50% examples, 222490 words/s, in_qsize 1, out_qsize 0
[2021-01-21 23:14:06,765] INFO: worker thread finished; awaiting finish of 0 more threads
[2021-01-21 23:14:06,766] INFO: EPOCH - 2 : training on 1225857 raw words (596009 effective words) took 2.5s, 238504 effective words/s
[2021-01-21 23:14:07,797] INFO: EPOCH 3 - PROGRESS: at 50.52% examples, 301522 words/s, in_qsize 1, out_qsize 0
[2021-01-21 23:14:08,769] INFO: worker thread finished; awaiting finish of 0 more threads
[2021-01-21 23:14:08,770] INFO: EPOCH - 3 : training on 1225857 raw words (595367 effective words) took 2.0s, 299480 effective words/s
[2021-01-21 23:14:09,794] INFO: EPOCH 4 - PROGRESS: at 50.52% examples, 301992 words/s, in_qsize 1, out_qsize 0
[2021-01-21 23:14:10,798] INFO: EPOCH 4 - PROGRESS: at 85.92% examples, 249391 words/s, in_qsize 1, out_qsize 0
[2021-01-21 23:14:11,223] INFO: worker thread finished; awaiting finish of 0 more threads
[2021-01-21 23:14:11,224] INFO: EPOCH - 4 : training on 1225857 raw words (594955 effective words) took 2.4s, 243607 effective words/s
[2021-01-21 23:14:12,247] INFO: EPOCH 5 - PROGRESS: at 36.65% examples, 233100 words/s, in_qsize 1, out_qsize 0
[2021-01-21 23:14:13,248] INFO: EPOCH 5 - PROGRESS: at 82.88% examples, 239959 words/s, in_qsize 1, out_qsize 0
[2021-01-21 23:14:13,898] INFO: worker thread finished; awaiting finish of 0 more threads
[2021-01-21 23:14:13,899] INFO: EPOCH - 5 : training on 1225857 raw words (594274 effective words) took 2.7s, 223014 effective words/s
[2021-01-21 23:14:13,899] INFO: training on a 6129285 raw words (2975502 effective words) took 11.6s, 256163 effective words/s
[2021-01-21 23:14:13,959] INFO: resetting layer weights
[2021-01-21 23:14:29,228] INFO: collecting all words and their counts
[2021-01-21 23:14:29,289] WARNING: Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.
[2021-01-21 23:14:29,290] INFO: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
[2021-01-21 23:14:29,383] INFO: PROGRESS: at sentence #10000, processed 262639 words, keeping 27 word types
[2021-01-21 23:14:29,478] INFO: PROGRESS: at sentence #20000, processed 531242 words, keeping 27 word types
[2021-01-21 23:14:29,563] INFO: PROGRESS: at sentence #30000, processed 753527 words, keeping 27 word types
[2021-01-21 23:14:29,574] INFO: collected 27 word types from a corpus of 780929 raw words and 31102 sentences
[2021-01-21 23:14:29,575] INFO: Loading a fresh vocabulary
[2021-01-21 23:14:29,575] INFO: effective_min_count=1 retains 27 unique words (100% of original 27, drops 0)
[2021-01-21 23:14:29,576] INFO: effective_min_count=1 leaves 780929 word corpus (100% of original 780929, drops 0)
[2021-01-21 23:14:29,577] INFO: deleting the raw counts dictionary of 27 items
[2021-01-21 23:14:29,577] INFO: sample=0.001 downsamples 24 most-common words
[2021-01-21 23:14:29,578] INFO: downsampling leaves estimated 132965 word corpus (17.0% of prior 780929)
[2021-01-21 23:14:29,579] INFO: estimated required memory for 27 words, 27 buckets and 100 dimensions: 47412 bytes
[2021-01-21 23:14:29,579] INFO: resetting layer weights
[2021-01-21 23:14:34,584] INFO: training model with 1 workers on 27 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
[2021-01-21 23:14:35,260] INFO: worker thread finished; awaiting finish of 0 more threads
[2021-01-21 23:14:35,260] INFO: EPOCH - 1 : training on 780929 raw words (133016 effective words) took 0.7s, 200398 effective words/s
[2021-01-21 23:14:35,931] INFO: worker thread finished; awaiting finish of 0 more threads
[2021-01-21 23:14:35,932] INFO: EPOCH - 2 : training on 780929 raw words (132930 effective words) took 0.7s, 201011 effective words/s
[2021-01-21 23:14:36,615] INFO: worker thread finished; awaiting finish of 0 more threads
[2021-01-21 23:14:36,616] INFO: EPOCH - 3 : training on 780929 raw words (133233 effective words) took 0.7s, 197710 effective words/s
[2021-01-21 23:14:37,268] INFO: worker thread finished; awaiting finish of 0 more threads
[2021-01-21 23:14:37,269] INFO: EPOCH - 4 : training on 780929 raw words (133807 effective words) took 0.6s, 208015 effective words/s
[2021-01-21 23:14:37,955] INFO: worker thread finished; awaiting finish of 0 more threads
[2021-01-21 23:14:37,956] INFO: EPOCH - 5 : training on 780929 raw words (133240 effective words) took 0.7s, 196793 effective words/s
[2021-01-21 23:14:37,956] INFO: training on a 3904645 raw words (666226 effective words) took 3.4s, 197617 effective words/s
[2021-01-21 23:14:37,960] INFO: saving model_fasttext_bibl_bible_bcn
[2021-01-21 23:14:37,960] INFO: saving FastText object under /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_bible_bcn, separately None
[2021-01-21 23:14:37,962] INFO: storing np array 'vectors_ngrams' to /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_bible_bcn.wv.vectors_ngrams.npy
[2021-01-21 23:15:16,843] INFO: not storing attribute vectors_norm
[2021-01-21 23:15:16,863] INFO: not storing attribute vectors_vocab_norm
[2021-01-21 23:15:16,866] INFO: not storing attribute vectors_ngrams_norm
[2021-01-21 23:15:16,866] INFO: not storing attribute buckets_word
[2021-01-21 23:15:16,867] INFO: storing np array 'vectors_ngrams_lockf' to /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_bible_bcn.trainables.vectors_ngrams_lockf.npy
[2021-01-21 23:15:53,873] INFO: saved /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_bible_bcn
[2021-01-21 23:15:54,019] INFO: saved /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_bible_bcn
[2021-01-21 23:15:54,020] INFO: saving model_fasttext_bibl_content
[2021-01-21 23:15:54,020] INFO: saving FastText object under /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_content, separately None
[2021-01-21 23:15:54,021] INFO: storing np array 'vectors_ngrams' to /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_content.wv.vectors_ngrams.npy
[2021-01-21 23:16:32,209] INFO: not storing attribute vectors_norm
[2021-01-21 23:16:32,281] INFO: not storing attribute vectors_vocab_norm
[2021-01-21 23:16:32,282] INFO: not storing attribute vectors_ngrams_norm
[2021-01-21 23:16:32,282] INFO: not storing attribute buckets_word
[2021-01-21 23:16:32,283] INFO: storing np array 'vectors_ngrams_lockf' to /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_content.trainables.vectors_ngrams_lockf.npy
[2021-01-21 23:17:10,326] INFO: saved /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_content
[2021-01-21 23:17:10,329] INFO: saved /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_content
[2021-01-21 23:17:10,329] INFO: saving model_fasttext_bibl_econtent
[2021-01-21 23:17:10,330] INFO: saving FastText object under /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_econtent, separately None
[2021-01-21 23:17:10,331] INFO: storing np array 'vectors_ngrams' to /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_econtent.wv.vectors_ngrams.npy
[2021-01-21 23:17:46,966] INFO: not storing attribute vectors_norm
[2021-01-21 23:17:47,029] INFO: not storing attribute vectors_vocab_norm
[2021-01-21 23:17:47,030] INFO: not storing attribute vectors_ngrams_norm
[2021-01-21 23:17:47,030] INFO: not storing attribute buckets_word
[2021-01-21 23:17:47,031] INFO: storing np array 'vectors_ngrams_lockf' to /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_econtent.trainables.vectors_ngrams_lockf.npy
[2021-01-21 23:18:23,806] INFO: saved /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_econtent
[2021-01-21 23:18:23,808] INFO: saved /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_econtent
[2021-01-21 23:18:36,357] INFO: loading model_word2vec_bibl_bible_bcn
[2021-01-21 23:18:36,358] INFO: loading Word2Vec object from /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_word2vec_bibl_bible_bcn
[2021-01-21 23:18:36,363] INFO: loading wv recursively from /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_word2vec_bibl_bible_bcn.wv.* with mmap=None
[2021-01-21 23:18:36,364] INFO: setting ignored attribute vectors_norm to None
[2021-01-21 23:18:36,365] INFO: loading vocabulary recursively from /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_word2vec_bibl_bible_bcn.vocabulary.* with mmap=None
[2021-01-21 23:18:36,366] INFO: loading trainables recursively from /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_word2vec_bibl_bible_bcn.trainables.* with mmap=None
[2021-01-21 23:18:36,366] INFO: setting ignored attribute cum_table to None
[2021-01-21 23:18:36,367] INFO: loaded /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_word2vec_bibl_bible_bcn
[2021-01-21 23:18:36,368] INFO: load time:0.010146141052246094
[2021-01-21 23:18:37,373] INFO: pid:10695 done | load time: 1.0149791240692139
[2021-01-21 23:18:37,373] INFO: loading model_word2vec_bibl_content
[2021-01-21 23:18:37,374] INFO: loading Word2Vec object from /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_word2vec_bibl_content
[2021-01-21 23:18:37,393] INFO: loading wv recursively from /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_word2vec_bibl_content.wv.* with mmap=None
[2021-01-21 23:18:37,394] INFO: setting ignored attribute vectors_norm to None
[2021-01-21 23:18:37,394] INFO: loading vocabulary recursively from /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_word2vec_bibl_content.vocabulary.* with mmap=None
[2021-01-21 23:18:37,395] INFO: loading trainables recursively from /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_word2vec_bibl_content.trainables.* with mmap=None
[2021-01-21 23:18:37,395] INFO: setting ignored attribute cum_table to None
[2021-01-21 23:18:37,396] INFO: loaded /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_word2vec_bibl_content
[2021-01-21 23:18:37,399] INFO: load time:0.02529001235961914
[2021-01-21 23:18:38,401] INFO: pid:10695 done | load time: 1.0268118381500244
[2021-01-21 23:18:38,401] INFO: loading model_word2vec_bibl_econtent
[2021-01-21 23:18:38,401] INFO: loading Word2Vec object from /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_word2vec_bibl_econtent
[2021-01-21 23:18:38,404] INFO: loading wv recursively from /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_word2vec_bibl_econtent.wv.* with mmap=None
[2021-01-21 23:18:38,404] INFO: setting ignored attribute vectors_norm to None
[2021-01-21 23:18:38,405] INFO: loading vocabulary recursively from /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_word2vec_bibl_econtent.vocabulary.* with mmap=None
[2021-01-21 23:18:38,405] INFO: loading trainables recursively from /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_word2vec_bibl_econtent.trainables.* with mmap=None
[2021-01-21 23:18:38,406] INFO: setting ignored attribute cum_table to None
[2021-01-21 23:18:38,406] INFO: loaded /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_word2vec_bibl_econtent
[2021-01-21 23:18:38,407] INFO: load time:0.0053369998931884766
[2021-01-21 23:18:39,412] INFO: pid:10695 done | load time: 1.0104820728302002
[2021-01-21 23:18:47,607] INFO: loading model_fasttext_bibl_bible_bcn
[2021-01-21 23:18:47,608] INFO: loading FastText object from /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_bible_bcn
[2021-01-21 23:18:47,612] INFO: loading wv recursively from /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_bible_bcn.wv.* with mmap=None
[2021-01-21 23:18:47,612] INFO: loading vectors_ngrams from /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_bible_bcn.wv.vectors_ngrams.npy with mmap=None
[2021-01-21 23:18:49,384] INFO: setting ignored attribute vectors_norm to None
[2021-01-21 23:18:49,385] INFO: setting ignored attribute vectors_vocab_norm to None
[2021-01-21 23:18:49,386] INFO: setting ignored attribute vectors_ngrams_norm to None
[2021-01-21 23:18:49,387] INFO: setting ignored attribute buckets_word to None
[2021-01-21 23:18:49,388] INFO: loading vocabulary recursively from /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_bible_bcn.vocabulary.* with mmap=None
[2021-01-21 23:18:49,389] INFO: loading trainables recursively from /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_bible_bcn.trainables.* with mmap=None
[2021-01-21 23:18:49,389] INFO: loading vectors_ngrams_lockf from /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_bible_bcn.trainables.vectors_ngrams_lockf.npy with mmap=None
[2021-01-21 23:18:52,341] INFO: loaded /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_bible_bcn
[2021-01-21 23:18:52,344] INFO: load time:4.735778093338013
[2021-01-21 23:18:53,348] INFO: pid:10695 done | load time: 5.740655899047852
[2021-01-21 23:18:53,349] INFO: loading model_fasttext_bibl_content
[2021-01-21 23:18:53,350] INFO: loading FastText object from /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_content
[2021-01-21 23:18:53,371] INFO: loading wv recursively from /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_content.wv.* with mmap=None
[2021-01-21 23:18:53,372] INFO: loading vectors_ngrams from /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_content.wv.vectors_ngrams.npy with mmap=None
[2021-01-21 23:18:55,105] INFO: setting ignored attribute vectors_norm to None
[2021-01-21 23:18:55,106] INFO: setting ignored attribute vectors_vocab_norm to None
[2021-01-21 23:18:55,107] INFO: setting ignored attribute vectors_ngrams_norm to None
[2021-01-21 23:18:55,107] INFO: setting ignored attribute buckets_word to None
[2021-01-21 23:18:55,108] INFO: loading vocabulary recursively from /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_content.vocabulary.* with mmap=None
[2021-01-21 23:18:55,108] INFO: loading trainables recursively from /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_content.trainables.* with mmap=None
[2021-01-21 23:18:55,108] INFO: loading vectors_ngrams_lockf from /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_content.trainables.vectors_ngrams_lockf.npy with mmap=None
[2021-01-21 23:18:56,766] INFO: loaded /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_content
[2021-01-21 23:18:56,776] INFO: load time:3.4258060455322266
[2021-01-21 23:18:57,776] INFO: pid:10695 done | load time: 4.426424980163574
[2021-01-21 23:18:57,777] INFO: loading model_fasttext_bibl_econtent
[2021-01-21 23:18:57,777] INFO: loading FastText object from /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_econtent
[2021-01-21 23:18:57,839] INFO: loading wv recursively from /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_econtent.wv.* with mmap=None
[2021-01-21 23:18:57,839] INFO: loading vectors_ngrams from /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_econtent.wv.vectors_ngrams.npy with mmap=None
[2021-01-21 23:18:59,405] INFO: setting ignored attribute vectors_norm to None
[2021-01-21 23:18:59,406] INFO: setting ignored attribute vectors_vocab_norm to None
[2021-01-21 23:18:59,407] INFO: setting ignored attribute vectors_ngrams_norm to None
[2021-01-21 23:18:59,407] INFO: setting ignored attribute buckets_word to None
[2021-01-21 23:18:59,407] INFO: loading vocabulary recursively from /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_econtent.vocabulary.* with mmap=None
[2021-01-21 23:18:59,408] INFO: loading trainables recursively from /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_econtent.trainables.* with mmap=None
[2021-01-21 23:18:59,408] INFO: loading vectors_ngrams_lockf from /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_econtent.trainables.vectors_ngrams_lockf.npy with mmap=None
[2021-01-21 23:19:01,288] INFO: loaded /Users/neo1/PycharmProjects/vec4irltr/model/ir/20210121231330551/model_fasttext_bibl_econtent
[2021-01-21 23:19:01,289] INFO: load time:3.512282133102417
[2021-01-21 23:19:02,295] INFO: pid:10695 done | load time: 4.517343997955322
